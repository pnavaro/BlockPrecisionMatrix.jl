{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall, Random, GLMNet, InvertedIndices, Statistics, Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×5 Array{Float64,2}:\n",
       " -1.20707   -0.564452   -0.51101   -0.69372    -0.70944 \n",
       "  0.277429  -0.890038   -0.911195  -1.4482     -0.501258\n",
       "  1.08444   -0.477193   -0.837172   0.574756   -1.62909 \n",
       " -2.3457    -0.998386    2.41584   -1.02366    -1.16762 \n",
       "  0.429125  -0.776254    0.134088  -0.0151383  -2.18004 \n",
       "  0.506056   0.0644588  -0.490686  -0.935949   -1.34099 \n",
       " -0.57474    0.959494   -0.440548   1.1023     -0.294294\n",
       " -0.546632  -0.110285    0.459589  -0.475593   -0.465898"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows, ncols = 8, 5\n",
    "@rput ncols\n",
    "@rput nrows\n",
    "R\"set.seed(1234)\"\n",
    "X = rcopy(R\"matrix(rnorm(nrows*ncols), nrows, ncols )\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Solution Path (73 solutions for 4 predictors in 337 passes):\n",
       "────────────────────────────────\n",
       "      df    pct_dev            λ\n",
       "────────────────────────────────\n",
       " [1]   0  0.0        0.806658   \n",
       " [2]   1  0.0994775  0.734997   \n",
       " [3]   1  0.182066   0.669702   \n",
       " [4]   1  0.250632   0.610207   \n",
       " [5]   1  0.307556   0.555998   \n",
       " [6]   1  0.354816   0.506605   \n",
       " [7]   1  0.394052   0.461599   \n",
       " [8]   1  0.426627   0.420592   \n",
       " [9]   1  0.45367    0.383228   \n",
       "[10]   1  0.476123   0.349183   \n",
       "[11]   1  0.494763   0.318162   \n",
       "[12]   1  0.510238   0.289898   \n",
       "[13]   2  0.547479   0.264144   \n",
       "[14]   2  0.591579   0.240678   \n",
       "[15]   2  0.628192   0.219297   \n",
       "[16]   2  0.658588   0.199815   \n",
       "[17]   2  0.683824   0.182064   \n",
       "[18]   2  0.704775   0.16589    \n",
       "[19]   2  0.722168   0.151153   \n",
       "[20]   2  0.736609   0.137725   \n",
       "[21]   2  0.748598   0.12549    \n",
       "[22]   2  0.758552   0.114342   \n",
       "[23]   2  0.766815   0.104184   \n",
       "[24]   2  0.773676   0.0949285  \n",
       "[25]   2  0.779371   0.0864953  \n",
       "[26]   2  0.7841     0.0788113  \n",
       "[27]   2  0.788026   0.0718099  \n",
       "[28]   2  0.791285   0.0654305  \n",
       "[29]   2  0.793991   0.0596178  \n",
       "[30]   2  0.796238   0.0543216  \n",
       "[31]   2  0.798103   0.0494958  \n",
       "[32]   2  0.799651   0.0450987  \n",
       "[33]   2  0.800937   0.0410923  \n",
       "[34]   2  0.802004   0.0374417  \n",
       "[35]   2  0.80289    0.0341155  \n",
       "[36]   3  0.804546   0.0310848  \n",
       "[37]   3  0.806013   0.0283233  \n",
       "[38]   3  0.807229   0.0258071  \n",
       "[39]   3  0.808239   0.0235145  \n",
       "[40]   3  0.809078   0.0214255  \n",
       "[41]   3  0.809774   0.0195222  \n",
       "[42]   3  0.810352   0.0177879  \n",
       "[43]   3  0.810832   0.0162076  \n",
       "[44]   3  0.811228   0.0147678  \n",
       "[45]   3  0.81156    0.0134559  \n",
       "[46]   3  0.811835   0.0122605  \n",
       "[47]   3  0.812063   0.0111713  \n",
       "[48]   4  0.812474   0.0101789  \n",
       "[49]   4  0.813058   0.00927461 \n",
       "[50]   4  0.813543   0.00845067 \n",
       "[51]   4  0.813945   0.00769994 \n",
       "[52]   4  0.814272   0.0070159  \n",
       "[53]   4  0.81455    0.00639263 \n",
       "[54]   4  0.814781   0.00582472 \n",
       "[55]   4  0.814973   0.00530727 \n",
       "[56]   4  0.815132   0.00483579 \n",
       "[57]   4  0.81526    0.00440619 \n",
       "[58]   4  0.81537    0.00401476 \n",
       "[59]   4  0.815462   0.0036581  \n",
       "[60]   4  0.815539   0.00333312 \n",
       "[61]   4  0.815602   0.00303702 \n",
       "[62]   4  0.815652   0.00276722 \n",
       "[63]   4  0.815696   0.00252138 \n",
       "[64]   4  0.815732   0.00229739 \n",
       "[65]   4  0.815763   0.0020933  \n",
       "[66]   4  0.815788   0.00190733 \n",
       "[67]   4  0.815807   0.00173789 \n",
       "[68]   4  0.815825   0.0015835  \n",
       "[69]   4  0.815839   0.00144283 \n",
       "[70]   4  0.815852   0.00131465 \n",
       "[71]   4  0.815862   0.00119786 \n",
       "[72]   4  0.81587    0.00109145 \n",
       "[73]   4  0.815876   0.000994486\n",
       "────────────────────────────────"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1\n",
    "fitreg = glmnet(X[:,Not(k)],X[:,k], standardize=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×73 CompressedPredictorMatrix:\n",
       " 0.0   0.0         0.0       0.0       …   0.247236    0.248887    0.250126 \n",
       " 0.0  -0.0691671  -0.13219  -0.189613     -0.806585   -0.806648   -0.806707 \n",
       " 0.0   0.0         0.0       0.0          -0.0900087  -0.0910518  -0.0918609\n",
       " 0.0   0.0         0.0       0.0          -0.901522   -0.902627   -0.903507 "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitreg.betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×73 Array{Float64,2}:\n",
       " -0.297136  -0.263356  -0.232578  …  -0.2213     -0.221642   -0.221901 \n",
       " -0.297136  -0.235677  -0.179677     -0.0987827  -0.0990805  -0.0992915\n",
       " -0.297136  -0.240797  -0.189463      0.778265    0.777781    0.777432 \n",
       " -0.297136  -0.465798  -0.619476     -2.24658    -2.24697    -2.24727  \n",
       " -0.297136  -0.307976  -0.317853      0.470709    0.470893    0.471078 \n",
       " -0.297136  -0.264762  -0.235264  …   0.508959    0.510604    0.511875 \n",
       " -0.297136  -0.26823   -0.241892     -0.43728    -0.437443   -0.437636 \n",
       " -0.297136  -0.33049   -0.360881     -1.13108    -1.13123    -1.13137  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(fitreg,X[:,Not(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prec_xia (generic function with 1 method)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prec_xia(X)\n",
    "\n",
    "    nrows, ncols = size(X)\n",
    "\n",
    "    betahat = zeros(Float64,(ncols-1,ncols))\n",
    "    reshat  = copy(X)\n",
    "\n",
    "    for k in 1:ncols\n",
    "      fitreg = glmnet(X[:,Not(k)],X[:,k], standardize=false) \n",
    "      betahat[:,k] .= vec(fitreg.betas)\n",
    "      reshat[:,k]  .= X[:,k] .- vec(predict(fitreg,X[:,Not(k)]))\n",
    "    end\n",
    "\n",
    "    rtilde = cov(reshat) .* (n-1) ./ n\n",
    "    rhat   = rtilde\n",
    "\n",
    "    for i in 1:ncols-1\n",
    "       for j in (i+1):ncols\n",
    "        rhat[i,j] = -(rtilde[i,j]+rtilde[i,i]*betahat[i,j]+rtilde[j,j]*betahat[j-1,i])\n",
    "        rhat[j,i] = rhat[i,j]\n",
    "      end\n",
    "    end\n",
    "\n",
    "    Tprec    = copy(1 ./ rhat)\n",
    "    TprecStd = copy(Tprec)\n",
    "\n",
    "    for i in 1:(ncols-1)\n",
    "        for j in (i+1):ncols\n",
    "            Tprec[i,j] = Tprec[j,i] = rhat[i,j]/(rhat[i,i]*rhat[j,j])\n",
    "            thetahatij = (1+(betahat[i,j]^2  * rhat[i,i]/rhat[j,j]))/(n*rhat[i,i]*rhat[j,j])   \n",
    "            TprecStd[i,j] = TprecStd[j,i] = Tprec[i,j]/sqrt(thetahatij)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    Tprec, TprecStd\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch(\"array could not be broadcast to match destination\")",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"array could not be broadcast to match destination\")",
      "",
      "Stacktrace:",
      " [1] check_broadcast_shape at ./broadcast.jl:503 [inlined]",
      " [2] check_broadcast_axes at ./broadcast.jl:506 [inlined]",
      " [3] instantiate at ./broadcast.jl:259 [inlined]",
      " [4] materialize! at ./broadcast.jl:801 [inlined]",
      " [5] prec_xia(::Array{Float64,2}) at ./In[97]:10",
      " [6] top-level scope at In[98]:1"
     ]
    }
   ],
   "source": [
    "prec_xia(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,jl:light",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".jl",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
